{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, spark init, dataset read"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "import numpy as np\n",
    "from pyspark.sql.functions import col\n",
    "import pyspark.sql.functions as sql_func\n",
    "from pyspark.sql.types import StructType, StructField, StringType, TimestampType, IntegerType, FloatType, BooleanType\n",
    "from functools import reduce\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import col"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def init_spark():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master('local[*]')\\\n",
    "        .appName(\"Python Spark SQL basic example\") \\\n",
    "        .config(\"spark.driver.memory\", \"15g\")\\\n",
    "        .getOrCreate()\n",
    "    return spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not need 'Country' column, since it only has one value, it is clear we work in the scope of USA, \n",
    "'id' provides no relevant information either, so can be dropped\n",
    "\n",
    "We also add a year column to easily distinguish on when the specific accdent occured"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "def read_dataset(filename):\n",
    "    spark = init_spark()\n",
    "    total_accidents_data = spark.read.csv(filename, header=True, mode=\"DROPMALFORMED\", encoding=\"ISO-8859-1\", inferSchema=True)\n",
    "    # dropped meaningless and 1 class only columns\n",
    "    final_result = total_accidents_data.drop('Country').drop('id')\\\n",
    "        .withColumn('start_year', sql_func.date_format(total_accidents_data.Start_Time, 'y'))\n",
    "      \n",
    "    return final_result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "root_accidents_data = read_dataset('data/US_Accidents_Dec20.csv')\n",
    "root_accidents_data.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reflect on the above output:\n",
    "TMC - is the accident code assigned by the authorities full list can be found here:\n",
    "https://wiki.openstreetmap.org/wiki/TMC/Event_Code_List"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# Total dataset count is:\n",
    "root_accidents_data.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis and cleanup, imbalance treatment, feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data source and meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DataFrame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-39a3b7dce52f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# we will use these functions to display a pie chart of a column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mdisplay_piechart_of_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccidents_dataframe\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumn_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcounted_accidents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccidents_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'string'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mgroupBy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DataFrame' is not defined"
     ]
    }
   ],
   "source": [
    "# we will use these functions to display a pie chart of a column\n",
    "def display_piechart_of_column(accidents_dataframe: DataFrame, column_name: str):\n",
    "    counted_accidents = accidents_dataframe.withColumn(column_name, col(column_name).cast('string'))\\\n",
    "        .groupBy(column_name).count()\n",
    "        \n",
    "    counted_accidents = counted_accidents.collect()\n",
    "    labels = [label[column_name] for label in counted_accidents]\n",
    "    counts = [label['count'] for label in counted_accidents]\n",
    "    count_sum = reduce(lambda x, y: x + y, counts)\n",
    "    percentages = [count/count_sum for count in counts]\n",
    "    piechart(labels, percentages, column_name)\n",
    "    zipped = [(labels[i], counts[i]) for i in range(len(labels))]\n",
    "    print(zipped)\n",
    "\n",
    "\n",
    "def piechart(labels, percentages, column_name):\n",
    "    plt.pie(percentages, labels=labels)\n",
    "    plt.title(f'ratio by {column_name}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display_piechart_of_column(root_accidents_data, 'Source')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above the data comes from 3 sources: MapQuest, Bing, and a mix up of MapQuest-Bing. There are about twice as many inputs from MapQuest compared to Bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bing = root_accidents_data.filter(col('Source') == 'Bing')\n",
    "display_piechart_of_column(bing, 'Severity')\n",
    "\n",
    "quest = root_accidents_data.filter(col('Source') == 'MapQuest')\n",
    "display_piechart_of_column(quest, 'Severity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as can be seen above, Bing and MapQuest have recorded a different ratios of severities of each level, It looks like Map Quest have stricter requirements for level 4, and such a minority of them was recorded over 5 years. Bing's chart while biased towards severity 2 displays more coverage on other categories. We cannot use both datasets, and while it is hard to choose which one. #todo decide if should choose either or drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wind analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "us states analysis. Maybe just do regressions per state to reach better results since authorities mostly care about data within their state and not their neighbour's state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outlier Treatment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add weekday + display histogram statistics on per day basis (this is a screenshot override with out histogram)\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "add duration, drop end time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update wind direction property and map it to W if WNW for example\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "update weather conditions. If weather is calm then wind speed is 0 but it is null in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "update wind values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "turn start into year month day, hour minutes, drop start time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop TMC, End Lat, End lng, distance (ml) since these can only be gathered post factum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "drop description since POI are accessible via other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
